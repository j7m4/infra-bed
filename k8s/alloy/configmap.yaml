apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config
  namespace: observability
data:
  config.alloy: |
    // ⚠️ PROOF-OF-CONCEPT CONFIGURATION ⚠️
    // This configuration is for demonstration purposes only.
    // DO NOT use in production without proper security hardening!
    // 
    // Insecure settings used:
    // - tls.insecure = true
    // - No authentication
    // - Default endpoints and ports
    
    otelcol.receiver.otlp "default" {
      grpc {
        endpoint = "0.0.0.0:4317"
      }
      http {
        endpoint = "0.0.0.0:4318"
      }
      output {
        traces = [otelcol.processor.batch.default.input]
      }
    }

    otelcol.processor.batch "default" {
      output {
        traces = [otelcol.exporter.otlp.tempo.input]
      }
    }

    otelcol.exporter.otlp "tempo" {
      client {
        endpoint = "lgtm:4317"
        tls {
          insecure = true
        }
      }
    }

    // CROSS-CUTTING START OF alloy CONFIGURATION FOR go-spikes
    discovery.kubernetes "go_spikes" {
      role = "pod"
      selectors {
        role = "pod"
        label = "app=go-spikes"
      }
    }
    
    discovery.relabel "go_spikes_pprof" {
      targets = discovery.kubernetes.go_spikes.targets
    
      rule {
        // Keep only the targets where the container port is 6060.
        action       = "keep"
        source_labels = ["__meta_kubernetes_pod_container_port_number"]
        regex        = "6060"
      }
    
      rule {
        // Take the pod's IP address and the discovered port number
        // and combine them to form the final scrape address.
        action       = "replace"
        source_labels = ["__meta_kubernetes_pod_ip", "__meta_kubernetes_pod_container_port_number"]
        regex        = "([^:]+);(\\d+)" // Capture IP and port
        replacement  = "$1:$2"         // Combine them as "ip:port"
        target_label = "__address__"
      }
    }

    pyroscope.scrape "pprof" {
      targets    = discovery.relabel.go_spikes_pprof.output
      forward_to = [pyroscope.write.lgtm.receiver]
    
      profiling_config {
        profile.process_cpu {
          enabled = true
        }
        profile.memory {
          enabled = true
        }
        profile.goroutine {
          enabled = true
        }
        profile.mutex {
          enabled = true
        }
      }
    }

    pyroscope.write "lgtm" {
      endpoint {
        url = "http://pyroscope.observability:4040"
      }
    }
    // CROSS-CUTTING END OF alloy CONFIGURATION FOR go-spikes
    
    // CROSS-CUTTING START OF alloy CONFIGURATION FOR kafka
    discovery.kubernetes "kafka_exporter" {
      role = "pod"
      selectors {
        role = "pod"
        label = "app=kafka-exporter"
      }
    }

    prometheus.scrape "kafka_exporter" {
      targets = discovery.kubernetes.kafka_exporter.targets
      forward_to = [otelcol.receiver.prometheus.default.receiver]
      scrape_interval = "30s"
    }
    // CROSS-CUTTING END OF alloy CONFIGURATION FOR kafka
    
    // CROSS-CUTTING START OF alloy CONFIGURATION FOR mysql
    discovery.kubernetes "mysql_exporter" {
      role = "pod"
      selectors {
        role = "pod"
        label = "app=mysql-exporter"
      }
    }

    prometheus.scrape "mysql_exporter" {
      targets = discovery.kubernetes.mysql_exporter.targets
      forward_to = [otelcol.receiver.prometheus.default.receiver]
      scrape_interval = "30s"
    }
    // CROSS-CUTTING END OF alloy CONFIGURATION FOR mysql
    
    // CROSS-CUTTING START OF alloy CONFIGURATION FOR postgres
    discovery.kubernetes "postgres_exporter" {
      role = "pod"
      selectors {
        role = "pod"
        label = "app=postgres-exporter"
      }
    }

    prometheus.scrape "postgres_exporter" {
      targets = discovery.kubernetes.postgres_exporter.targets
      forward_to = [otelcol.receiver.prometheus.default.receiver]
      scrape_interval = "30s"
    }
    // CROSS-CUTTING END OF alloy CONFIGURATION FOR postgres
    
    // Kube-state-metrics scraping
    discovery.kubernetes "kube_state_metrics" {
      role = "pod"
      selectors {
        role = "pod"
        label = "app=kube-state-metrics"
      }
    }

    prometheus.scrape "kube_state_metrics" {
      targets = discovery.kubernetes.kube_state_metrics.targets
      forward_to = [otelcol.receiver.prometheus.default.receiver]
      scrape_interval = "30s"
    }
    
    // CROSS-CUTTING START OF otel-metrics CONFIGURATION FOR mimir
    // Convert Prometheus metrics to OTLP
    otelcol.receiver.prometheus "default" {
      output {
        metrics = [otelcol.processor.batch.metrics.input]
      }
    }
    
    otelcol.processor.batch "metrics" {
      output {
        metrics = [otelcol.exporter.otlp.lgtm_metrics.input]
      }
    }
    
    // Send metrics to LGTM via OTLP
    otelcol.exporter.otlp "lgtm_metrics" {
      client {
        endpoint = "lgtm:4317"
        tls {
          insecure = true
        }
      }
    }
    // CROSS-CUTTING END OF otel-metrics CONFIGURATION FOR mimir
    